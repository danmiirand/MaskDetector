{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi9nnYCFRRgT"
      },
      "source": [
        "## Bibliotecas utilizadas\n",
        "from PIL import Image\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LW_Uinza53Z"
      },
      "source": [
        "## Subindo imagem\n",
        "def select_image(filename):\n",
        "    # load image from file\n",
        "    image = Image.open(filename)\n",
        "    # convert to RGB, if needed\n",
        "    image = image.convert('RGB')\n",
        "    image = image.resize((160,160))\n",
        "    # convert to array\n",
        "    return np.asarray(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xr77Gc7bn5z"
      },
      "source": [
        "## Subindo classe\n",
        "def select_data_set(diretorio):\n",
        "\n",
        "    imagens = list()\n",
        "    labels = list()\n",
        "\n",
        "    for subdir in listdir(diretorio):\n",
        "        # path\n",
        "        path = diretorio + subdir + '\\\\'\n",
        "\n",
        "        if not isdir(path):\n",
        "            continue\n",
        "        imagens, labels = load_classes(path, subdir, imagens, labels)\n",
        "\n",
        "    return imagens, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTH59sA_boXZ"
      },
      "source": [
        "## Selecionando Dataset\n",
        "covid_dataset = \"C:\\\\dataset\\\\Mask\\\\faces\\\\\"\n",
        "imagens, labels  = select_data_set(covid_dataset)\n",
        "imagens = np.array(imagens) / 255.0  ## convertendo de lista para array\n",
        "labels = np.array(labels)  ## convertendo de lista para array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuVE1JNFbobD"
      },
      "source": [
        "## Carregando Dataset\n",
        "covid_dataset = \"D:\\\\dataset\\\\Mask\\\\faces\\\\\"\n",
        "imagens, labels  = select_data_set(covid_dataset)\n",
        "imagens = np.array(imagens) / 255.0  ## convertendo de lista para array\n",
        "labels = np.array(labels)  ## convertendo de lista para array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cae7wwJQgkid"
      },
      "source": [
        "## labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZMxn0GFboeK"
      },
      "source": [
        "## hyperparametros\n",
        "batch_size   = 32\n",
        "input_shape  = (160, 160, 3)\n",
        "random_state = 42\n",
        "alpha        = 1e-5\n",
        "epoch        = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsLbMLembohH"
      },
      "source": [
        "## Callbacks\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebPh7XzVboj5"
      },
      "source": [
        "filepath=\"detector.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scQNlb1Nbomb"
      },
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=alpha, patience=5, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtZEJfbib_yq"
      },
      "source": [
        "callbacks = [checkpoint, lr_reduce]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFqABvA1cCgT"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(imagens, labels, test_size=0.20, stratify=labels, random_state=random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRAmLVETcHXD"
      },
      "source": [
        "## Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "        horizontal_flip= True,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        fill_mode='nearest'\n",
        "        )\n",
        "\n",
        "train_datagen.fit(trainX)\n",
        "\n",
        "data_aug = train_datagen.flow(trainX, trainY, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH-uYgVzcHgA"
      },
      "source": [
        "## Transfer Learning\n",
        "conv_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zebnhqNmcHiw"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYiquwPFcHlr"
      },
      "source": [
        "## Retreinando VGG19\n",
        "conv_base.trainable = True\n",
        "set_trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df_O5BUQfoi1"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eaa7Y-JtfquA"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ywCkvCVftYV"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piDrc3MLfuAv"
      },
      "source": [
        "history = model.fit_generator(\n",
        "                              data_aug,\n",
        "                              steps_per_epoch=len(trainX)// batch_size, # parte inteira da divisão\n",
        "                              validation_data=(testX, testY),\n",
        "                              validation_steps=len(testX) // batch_size,# parte inteira da divisão\n",
        "                              callbacks=callbacks,\n",
        "                              epochs=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG0NL-3Cf2tL"
      },
      "source": [
        "## Dados em análise\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF8GZug0f3gq"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZuMPBAzf3p0"
      },
      "source": [
        "## Matriz de confusão\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = model.predict(testX)\n",
        "pred = np.argmax(pred,axis = 1) \n",
        "y_true = np.argmax(testY,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPQy5PLf3sz"
      },
      "source": [
        "cm = confusion_matrix(y_true, pred)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "print(\"Acurácia: {:.4f}\".format(acc))\n",
        "print(\"Sensitividade: {:.4f}\".format(sensitivity))\n",
        "print(\"Especificidade: {:.4f}\".format(specificity))\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=cm ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}